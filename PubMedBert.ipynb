{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "326700ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 10:07:15.517645: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-30 10:07:16.188139: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-30 10:07:16.188176: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-30 10:07:16.293789: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-05-30 10:07:17.693705: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-30 10:07:17.693899: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-30 10:07:17.693918: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/elahehaa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             classification_report, confusion_matrix)\n",
    "import transformers\n",
    "from transformers import (AutoTokenizer , AutoModelForSequenceClassification, TrainingArguments, \n",
    "                          Trainer, pipeline, DataCollatorWithPadding, AutoModelForSeq2SeqLM, \n",
    "                          EarlyStoppingCallback, IntervalStrategy)\n",
    "from datasets import load_dataset, Dataset, load_metric\n",
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "import wandb\n",
    "import collections\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import collections\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb010e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22c17684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 11% | 13% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 24% | 14% |\n"
     ]
    }
   ],
   "source": [
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c38c2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "def load_data(train_file_path, valid_file_path):\n",
    "    if train_file_path and valid_file_path:\n",
    "        dataset = load_dataset(\"csv\", data_files = {'train': train_file_path, 'validation': valid_file_path})\n",
    "    elif not valid_file_path:\n",
    "        dataset = load_dataset(\"csv\", data_files = {'train': train_file_path})\n",
    "    return dataset\n",
    "model_checkpoint = 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
    "def tokenize_data(example):\n",
    "    return tokenizer(preprocess(example['text']),  padding = 'max_length', truncation=True, max_length=max_length)\n",
    "#training and validation - 60/40\n",
    "#dataset = load_data(['RT_train.csv'],  ['RT_test.csv'])\n",
    "#train_tokenized = dataset['train'].map(tokenize_data, batched = True) \n",
    "#valid_tokenized = dataset['validation'].map(tokenize_data, batched = True)\n",
    "\n",
    "# training with whole data for deployment\n",
    "#dataset = load_data(['RT_train.csv', 'RT_test.csv'], None)\n",
    "#train_tokenized = dataset['train'].map(tokenize_data, batched = True)\n",
    "\n",
    "#training with whole data + 50% coded 2021 data, validating on 50% coded 2021\n",
    "#dataset = load_data(['RT_train.csv','RT_test.csv', 'RT_train_2021_j.csv'], ['RT_test_2021_j.csv'])\n",
    "#dataset = load_data(['RT_j.csv', 'RT_train_2021_j.csv'], ['RT_test_2021_j.csv'])\n",
    "#train_tokenized = dataset['train'].map(tokenize_data, batched = True)\n",
    "#valid_tokenized = dataset['validation'].map(tokenize_data, batched = True)\n",
    "\n",
    "#training with whole data + 50% coded 2021 data, validating on 50% coded 2021, removing No Abstract Available (second)\n",
    "#dataset = load_data(['RT_train.csv','RT_test.csv', 'RT_train_2021_j.csv'], ['RT_test_2021_j.csv'])\n",
    "#dataset = load_data(['RT_j_second.csv', 'RT_train_2021_j_second.csv'], ['RT_test_2021_j_second.csv'])\n",
    "#train_tokenized = dataset['train'].map(tokenize_data, batched = True)\n",
    "#valid_tokenized = dataset['validation'].map(tokenize_data, batched = True)\n",
    "\n",
    "#training with whole data + 50% coded 2021 data, validating on 50% coded 2021, separate abstract and title\n",
    "#dataset = load_data(['RT_s.csv', 'RT_train_2021_s.csv', 'RT_test_2021_s.csv'], None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8d1d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ebf4f7f31e28ef9f\n",
      "Found cached dataset csv (/home/elahehaa/.cache/huggingface/datasets/csv/default-ebf4f7f31e28ef9f/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7c4c3b5eda404b9a9c3d9c25208e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f09c279e3494fe1a805d47d4aec7d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9562/3923623124.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trainPrevention.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m'validPrevention.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mvalid_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2815\u001b[0;31m             return self._map_single(\n\u001b[0m\u001b[1;32m   2816\u001b[0m                 \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m                 \u001b[0mwith_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m         }\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   3234\u001b[0m                         )  # Something simpler?\n\u001b[1;32m   3235\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m                             batch = apply_function_on_filtered_inputs(\n\u001b[0m\u001b[1;32m   3237\u001b[0m                                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3111\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3112\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3114\u001b[0m                 processed_inputs = {\n",
      "\u001b[0;32m/tmp/ipykernel_9562/3923623124.py\u001b[0m in \u001b[0;36mtokenize_data\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdata_collator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataCollatorWithPadding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'max_length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trainPrevention.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m[\u001b[0m\u001b[0;34m'validPrevention.csv'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtrain_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "#prevention\n",
    "max_length = 512\n",
    "def load_data(train_file_path, valid_file_path):\n",
    "    if train_file_path and valid_file_path:\n",
    "        dataset = load_dataset(\"csv\", data_files = {'train': train_file_path, 'validation': valid_file_path})\n",
    "    elif not valid_file_path:\n",
    "        dataset = load_dataset(\"csv\", data_files = {'train': train_file_path})\n",
    "    return dataset\n",
    "model_checkpoint = 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
    "def tokenize_data(example):\n",
    "    return tokenizer(preprocess(example['text']),  padding = 'max_length', truncation=True, max_length=max_length)\n",
    "dataset = load_data(['trainPrevention.csv'],  ['validPrevention.csv'])\n",
    "train_tokenized = dataset['train'].map(tokenize_data, batched = True) \n",
    "valid_tokenized = dataset['validation'].map(tokenize_data, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35908511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def model_init():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_checkpoint,\n",
    "        num_labels=4,\n",
    "        #id2label={index: label for index, label in enumerate(labels.names)},\n",
    "        #label2id={label: index for index, label in enumerate(labels.names)}\n",
    "    )\n",
    "    return model\n",
    "model = model_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a285d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "}\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "parameters_dict = {\n",
    "    'epochs': {\n",
    "        'values': [1,2,4]\n",
    "        },\n",
    "    'batch_size': {\n",
    "        'values': [4, 8, 16]\n",
    "        },\n",
    "    'learning_rate': {\n",
    "        'distribution': 'log_uniform_values',\n",
    "        'min': 2e-7,\n",
    "        'max': 2e-4\n",
    "    },\n",
    "    'weight_decay': {\n",
    "        'values': [0.0, 0.01, 0.005, 0.001]\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56040335",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project='ft_all+PK_PubMedBERT3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc2d78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize/process title and abstract separately\n",
    "def customized_data_collator(examples):\n",
    "    titles = [example['Title'] for example in examples]\n",
    "    abstracts = [example['Abstract'] for example in examples]\n",
    "    \n",
    "    tokenized_title = tokenizer(titles , padding = 'max_length', truncation=True, max_length=30)\n",
    "    tokenized_abstract = tokenizer(abstracts, padding = 'max_length', truncation=True, max_length=256)\n",
    "    \n",
    "    #inputs = {\n",
    "        #'input_ids' : torch.cat([tokenized_title['input_ids'] , tokenized_abstract['input_ids']], dim =1),\n",
    "        #'attention_mask': torch.cat([tokenized_title['attention_mask'] , tokenized_abstract['attention_mask']], dim =1),\n",
    "        #'token_type_ids' : torch.cat([tokenized_title['token_type_ids'] , tokenized_abstract['token_type_ids']], dim =1)\n",
    "    #}\n",
    "    \n",
    "    inputs = {\n",
    "        'input_ids' : [a+b for a,b in zip(tokenized_title['input_ids'],tokenized_abstract['input_ids'])],\n",
    "        'attention_mask': [a+b for a,b in zip(tokenized_title['attention_mask'],tokenized_abstract['attention_mask'])],\n",
    "        'token_type_ids' : [a+b for a,b in zip(tokenized_title['token_type_ids'],tokenized_abstract['token_type_ids'])]\n",
    "    }\n",
    "    \n",
    "    label = [example['labels'] for example in examples]\n",
    "    batch = {\n",
    "        'input_ids': torch.tensor(inputs['input_ids']),\n",
    "        'attention_mask': torch.tensor(inputs['attention_mask']),\n",
    "        'token_type_ids': torch.tensor(inputs['token_type_ids']),\n",
    "        'labels': torch.tensor(label)\n",
    "    }\n",
    "    \n",
    "    return batch\n",
    "#print(customized_data_collator(dataset['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00265206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a test to find if tokenize and then merge title and abstract values will be different from first merge and then tokenize\n",
    "tokenized_t = tokenizer(dataset['train']['Title'][15] , padding = 'max_length', truncation=True, max_length=max_length)\n",
    "tokenized_a = tokenizer(dataset['train']['Abstract'][15] , padding = 'max_length', truncation=True, max_length=max_length)\n",
    "tokenized_ta = tokenizer(dataset['train']['Title'][15]+dataset['train']['Abstract'][15] , padding = 'max_length', truncation=True, max_length=max_length)\n",
    "print([a+b for a,b in zip(tokenized_t['input_ids'],tokenized_a['input_ids'])])\n",
    "print(tokenized_ta['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "233311f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to compute metrics\n",
    "def compute_metrics_fn(eval_preds):\n",
    "    \n",
    "    res = dict()\n",
    "\n",
    "    accuracy_metric = load_metric('accuracy')\n",
    "    precision_metric = load_metric('precision')\n",
    "    recall_metric = load_metric('recall')\n",
    "    f1_metric = load_metric('f1')\n",
    "    \n",
    "    logits = eval_preds.predictions\n",
    "    labels = eval_preds.label_ids\n",
    "    preds = np.argmax(logits, axis=-1)  \n",
    "    \n",
    "    report = classification_report(labels, preds)\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    print(report)\n",
    "    print('confusion matrix: ', cm)\n",
    "    \n",
    "    res.update(accuracy_metric.compute(predictions=preds, references=labels))\n",
    "    res.update(precision_metric.compute(predictions=preds, references=labels, average='macro'))\n",
    "    res.update(recall_metric.compute(predictions=preds, references=labels, average='macro'))\n",
    "    res.update(f1_metric.compute(predictions=preds, references=labels, average='macro'))\n",
    "    \n",
    "    return res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47e96b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiments using 60/40 - hyperparam tuning\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='ft_all+PK_PubMedBERT3',\n",
    "            report_to='wandb', \n",
    "            num_train_epochs=config.epochs,\n",
    "            learning_rate=config.learning_rate,\n",
    "            weight_decay=config.weight_decay,\n",
    "            per_device_train_batch_size=config.batch_size,\n",
    "            per_device_eval_batch_size=16,\n",
    "            save_strategy='epoch',\n",
    "            evaluation_strategy='epoch',\n",
    "            logging_strategy='epoch',\n",
    "            load_best_model_at_end=True,\n",
    "            remove_unused_columns=False,\n",
    "            fp16=True,\n",
    "            save_total_limit = 1,\n",
    "            run_name= 'ft_all+PK_PubMedBERT3',\n",
    "        )\n",
    "        \n",
    "\n",
    "        trainer = Trainer(\n",
    "            model_init=model_init,\n",
    "            args=training_args,\n",
    "            train_dataset=train_tokenized,\n",
    "            eval_dataset=valid_tokenized,\n",
    "            compute_metrics=compute_metrics_fn\n",
    "        )\n",
    "\n",
    "\n",
    "        trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf19dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, train, count=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbc7e41e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_tokenized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2355/646737096.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#prevention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.098e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ft_prevention_PubMedBERT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2355/646737096.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(learning_rate, weight_decay, run_name, epochs, batch_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel_init\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_tokenized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalid_tokenized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcompute_metrics_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_tokenized' is not defined"
     ]
    }
   ],
   "source": [
    "#candidate model more epochs\n",
    "def train(learning_rate, weight_decay, run_name, epochs, batch_size):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir= run_name,\n",
    "        report_to='wandb', \n",
    "        num_train_epochs= epochs,\n",
    "        learning_rate= learning_rate,\n",
    "        weight_decay= weight_decay,\n",
    "        per_device_train_batch_size= batch_size,\n",
    "        per_device_eval_batch_size=16,\n",
    "        save_strategy='epoch',\n",
    "        evaluation_strategy='epoch',\n",
    "        logging_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        remove_unused_columns=False,\n",
    "        #fp16=True,\n",
    "        save_total_limit = 1,\n",
    "        run_name= run_name,\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model_init= model_init,\n",
    "        args= training_args,\n",
    "        train_dataset= train_tokenized,\n",
    "        eval_dataset= valid_tokenized,\n",
    "        compute_metrics= compute_metrics_fn\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer.train()\n",
    "#selected1\n",
    "#train(4.495e-5, 0, \"ft_all_PubMedBERT_selected1\", 10, 16)\n",
    "#selected2\n",
    "#train(2.896e-5, 0.01, \"ft_all_PubMedBERT_selected2\", 10, 8)\n",
    "#selected3 - candidate\n",
    "#train(1.098e-4, 0.01, \"ft_all_PubMedBERT_selected32\", 10, 8)\n",
    "#PubMedBERT3selected\n",
    "#train(4.3e-5, 0.01, \"ft_all+PK_PubMedBERT3_selected2\", 4, 16)\n",
    "\n",
    "#prevention\n",
    "train(1.098e-4, 0.01, \"ft_prevention_PubMedBERT\", 1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df3fcbba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train final model with all data - test with early stopping , return to normal if did not work, add class weights\n",
    "torch.manual_seed(42)\n",
    "class CustomTrainer(Trainer):\n",
    "    def calculate_class_weights(training_set):\n",
    "        print(\"hi\")\n",
    "        labels = [set(training_set)]\n",
    "        class_distribution = [0]*len(labels)\n",
    "        for i in labels:\n",
    "            class_distribution[i] = training_set.count(i)\n",
    "        weights = []\n",
    "        class_distribution = np.array(class_distribution)\n",
    "        num_classes = len(labels)\n",
    "        weight = np.sum(class_distribution)/(num_classes * class_distribution)\n",
    "        return weight\n",
    "    def compute_custom_loss(model, inputs, return_outputs=False):\n",
    "        target = inputs.get('labels')\n",
    "        weights = calculate_class_weights(target)\n",
    "        print(weights)\n",
    "        print(\"hi2\")\n",
    "        ce_loss = nn.CrossEntropyLoss(weight=torch.tensor(weights))\n",
    "        outputs = model(*inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        probs = nn.functional.softmax(logits, dim = -1)\n",
    "        \n",
    "        loss = ce_loss(probs.view(-1, model.config.num_labels), target.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "def train(train_set, validation_set, learning_rate, weight_decay, run_name, epochs, batch_size):\n",
    "    mlflow.start_run()\n",
    "\n",
    "    # Log training parameters\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"num_epochs\", epochs)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir= run_name,\n",
    "        num_train_epochs= epochs,\n",
    "        learning_rate= learning_rate,\n",
    "        weight_decay= weight_decay,\n",
    "        per_device_train_batch_size= batch_size,\n",
    "        save_strategy= 'epoch' ,#IntervalStrategy.STEPS,\n",
    "        logging_strategy= 'epoch', #IntervalStrategy.STEPS,\n",
    "        remove_unused_columns=False,\n",
    "        save_total_limit = 1,\n",
    "        run_name= run_name,\n",
    "        fp16 = True,\n",
    "        load_best_model_at_end=True,\n",
    "        evaluation_strategy = 'epoch', #IntervalStrategy.STEPS,\n",
    "        eval_steps = 1,\n",
    "        metric_for_best_model = 'eval_f1',\n",
    "        seed = 42\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model_init= model_init,\n",
    "        args= training_args,\n",
    "        #train_tokenized for joined title and abstract, dataset['train'] for seperate title and abstract\n",
    "        train_dataset= train_set,\n",
    "        #use to create seperate title and abstract\n",
    "        data_collator = customized_data_collator,\n",
    "        compute_metrics= compute_metrics_fn,\n",
    "        #valid_tokenized for joined title and abstract, dataset['validation'] for seperate title and abstract\n",
    "        eval_dataset = validation_set,\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "        \n",
    "    )\n",
    "\n",
    "\n",
    "    trainer.train()\n",
    "    eval_result = trainer.evaluate()\n",
    "    mlflow.end_run()\n",
    "\n",
    "    return eval_result\n",
    "\n",
    "\n",
    "#final model training with all data\n",
    "#train(1.098e-4, 0.01, \"final_PubMedBERT_longer_longerepoch\", 5, 8)\n",
    "#final model training with all data + 50% coded 2021 data, joined abstract and title\n",
    "#train(1.098e-4, 0.01, \"final_PubMedBERT_2021\",4, 8)\n",
    "#final model training with all data + 50% coded 2021 data , separete title and abstract\n",
    "#train(train_set, test_set, 1.098e-4, 0.01, \"final_PubMedBERT_2021_separateInput\", 5, 8)\n",
    "\n",
    "#final model training with all data + 50% coded 2021 data , separate title and abstract\n",
    "#final = train(train_set, test_set, 1.098e-4, 0.01, \"final_PubMedBERT_2021_separateInput_v3\", 6, 8)\n",
    "#final = train(train_set, test_set, 1.098e-4, 0.01, \"final_PubMedBERT_2021_separateInput_test2\", 20, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ab50992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratified sampling to make sure enough sample from each class exists in the classification\n",
    "mlflow.end_run()\n",
    "# Set the experiment path\n",
    "experiment_path = \"PubClassifier\"\n",
    "\n",
    "# Set the experiment\n",
    "mlflow.set_experiment(experiment_path)\n",
    "#stratified k_fold cross validation for imbalanced dataset\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#heldout_set\n",
    "k_fold , test = next(skf.split(dataset['train'], dataset['train']['labels']))\n",
    "#kfold training and validation\n",
    "eval_result = []\n",
    "i = 0\n",
    "for train_idx , valid_idx in skf.split(dataset['train'][k_fold]['Title'], dataset['train'][k_fold]['labels']):\n",
    "    train_set = [dataset['train'][int(i)] for i in train_idx]\n",
    "    validation_set = [dataset['train'][int(i)] for i in valid_idx]\n",
    "    eval_result.append(train(train_set, validation_set, 3.098e-5, 0.001, \"PubMedBERT_2021_lr35\"+str(i), 10, 16))\n",
    "    i += 1\n",
    "    \n",
    "\n",
    "#1.098e-4, 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e98e8dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28899/2999843985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m#final model training with all data + 50% coded 2021 data , separate title and abstract\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.098e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"final_PubMedBERT_2021_separateInput_test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
     ]
    }
   ],
   "source": [
    "#class weights to imptove IRGT class performance\n",
    "class CustomTrainer(Trainer):\n",
    "    def calculate_class_weights(training_set):\n",
    "        print(\"hi\")\n",
    "        labels = [set(training_set)]\n",
    "        class_distribution = [0]*len(labels)\n",
    "        for i in labels:\n",
    "            class_distribution[i] = training_set.count(i)\n",
    "        weights = []\n",
    "        class_distribution = np.array(class_distribution)\n",
    "        num_classes = len(labels)\n",
    "        weight = np.sum(class_distribution)/(num_classes * class_distribution)\n",
    "        return weight\n",
    "    def compute_custom_loss(model, inputs, return_outputs=False):\n",
    "        target = inputs.get('labels')\n",
    "        weights = calculate_class_weights(target)\n",
    "        print(weights)\n",
    "        print(\"hi2\")\n",
    "        ce_loss = nn.CrossEntropyLoss(weight=torch.tensor(weights))\n",
    "        outputs = model(*inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        probs = nn.functional.softmax(logits, dim = -1)\n",
    "        \n",
    "        loss = ce_loss(probs.view(-1, model.config.num_labels), target.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "    \n",
    "def train(train_set, validation_set, learning_rate, weight_decay, run_name, epochs, batch_size):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir= run_name,\n",
    "        num_train_epochs= epochs,\n",
    "        learning_rate= learning_rate,\n",
    "        weight_decay= weight_decay,\n",
    "        per_device_train_batch_size= batch_size,\n",
    "        save_strategy='epoch',\n",
    "        logging_strategy='epoch',\n",
    "        remove_unused_columns=False,\n",
    "        save_total_limit = 1,\n",
    "        run_name= run_name,\n",
    "        fp16 = True\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model_init= model_init,\n",
    "        args= training_args,\n",
    "        #train_tokenized for joined title and abstract, dataset['train'] for seperate title and abstract\n",
    "        train_dataset= train_set,\n",
    "        #use to create seperate title and abstract\n",
    "        data_collator = customized_data_collator,\n",
    "        compute_metrics= compute_metrics_fn,\n",
    "        #valid_tokenized for joined title and abstract, dataset['validation'] for seperate title and abstract\n",
    "        eval_dataset = validation_set,\n",
    "        \n",
    "    )\n",
    "\n",
    "\n",
    "    trainer.train()\n",
    "    eval_result = trainer.evaluate()\n",
    "    return eval_result\n",
    "\n",
    "\n",
    "#final model training with all data\n",
    "#train(1.098e-4, 0.01, \"final_PubMedBERT_longer_longerepoch\", 5, 8)\n",
    "#final model training with all data + 50% coded 2021 data, joined abstract and title\n",
    "#train(1.098e-4, 0.01, \"final_PubMedBERT_2021\",4, 8)\n",
    "#final model training with all data + 50% coded 2021 data , separete title and abstract\n",
    "#train(train_set, test_set, 1.098e-4, 0.01, \"final_PubMedBERT_2021_separateInput\", 5, 8)\n",
    "\n",
    "#final model training with all data + 50% coded 2021 data , separate title and abstract\n",
    "final = train(train_set, test_set, 1.098e-4, 0.01, \"final_PubMedBERT_2021_separateInput_test\", 5, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14c7ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratified train and test set\n",
    "test_set = [dataset['train'][int(i)] for i in test]\n",
    "train_set = [dataset['train'][int(i)] for i in k_fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "417f1643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext/resolve/main/config.json from cache at /home/elahehaa/.cache/huggingface/transformers/76e7b0967140f134278c3209cffe98f69eb013b9de505a434b3359c057aedaa3.2411d0fafcf181e9b95d9cb7972d93b27c57a2cb75819924f8fc7ec848b708f2\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext/resolve/main/pytorch_model.bin from cache at /home/elahehaa/.cache/huggingface/transformers/41964abe9a7c4ccbc21929b6d256f1b79a5a39566e329b380fae9d0bf622f7b7.ca2d7d719ab41e712011b6e8381af6b4be73841c1e580600c522386c5ed9b6f0\n",
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cuda_amp half precision backend\n",
      "loading configuration file https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext/resolve/main/config.json from cache at /home/elahehaa/.cache/huggingface/transformers/76e7b0967140f134278c3209cffe98f69eb013b9de505a434b3359c057aedaa3.2411d0fafcf181e9b95d9cb7972d93b27c57a2cb75819924f8fc7ec848b708f2\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext/resolve/main/pytorch_model.bin from cache at /home/elahehaa/.cache/huggingface/transformers/41964abe9a7c4ccbc21929b6d256f1b79a5a39566e329b380fae9d0bf622f7b7.ca2d7d719ab41e712011b6e8381af6b4be73841c1e580600c522386c5ed9b6f0\n",
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/elahehaa/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2925\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 732\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='732' max='732' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [732/732 12:09, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.448500</td>\n",
       "      <td>0.257617</td>\n",
       "      <td>0.905738</td>\n",
       "      <td>0.686920</td>\n",
       "      <td>0.709270</td>\n",
       "      <td>0.696922</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.209677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>0.283669</td>\n",
       "      <td>0.919399</td>\n",
       "      <td>0.833679</td>\n",
       "      <td>0.856207</td>\n",
       "      <td>0.844052</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089600</td>\n",
       "      <td>0.311875</td>\n",
       "      <td>0.938525</td>\n",
       "      <td>0.883923</td>\n",
       "      <td>0.874187</td>\n",
       "      <td>0.878921</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.313196</td>\n",
       "      <td>0.935792</td>\n",
       "      <td>0.889207</td>\n",
       "      <td>0.875452</td>\n",
       "      <td>0.881781</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 732\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       439\n",
      "           1       0.82      0.95      0.88       238\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.97      0.97      0.97        35\n",
      "\n",
      "    accuracy                           0.91       732\n",
      "   macro avg       0.69      0.71      0.70       732\n",
      "weighted avg       0.89      0.91      0.89       732\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elahehaa/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/elahehaa/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/elahehaa/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/elahehaa/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to PubMedBERT_2021_test2/checkpoint-183\n",
      "Configuration saved in PubMedBERT_2021_test2/checkpoint-183/config.json\n",
      "Model weights saved in PubMedBERT_2021_test2/checkpoint-183/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 732\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       439\n",
      "           1       0.88      0.93      0.91       238\n",
      "           2       0.52      0.60      0.56        20\n",
      "           3       0.97      0.97      0.97        35\n",
      "\n",
      "    accuracy                           0.92       732\n",
      "   macro avg       0.83      0.86      0.84       732\n",
      "weighted avg       0.92      0.92      0.92       732\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to PubMedBERT_2021_test2/checkpoint-366\n",
      "Configuration saved in PubMedBERT_2021_test2/checkpoint-366/config.json\n",
      "Model weights saved in PubMedBERT_2021_test2/checkpoint-366/pytorch_model.bin\n",
      "Deleting older checkpoint [PubMedBERT_2021_test2/checkpoint-183] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 732\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       439\n",
      "           1       0.93      0.91      0.92       238\n",
      "           2       0.68      0.65      0.67        20\n",
      "           3       0.97      0.97      0.97        35\n",
      "\n",
      "    accuracy                           0.94       732\n",
      "   macro avg       0.88      0.87      0.88       732\n",
      "weighted avg       0.94      0.94      0.94       732\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to PubMedBERT_2021_test2/checkpoint-549\n",
      "Configuration saved in PubMedBERT_2021_test2/checkpoint-549/config.json\n",
      "Model weights saved in PubMedBERT_2021_test2/checkpoint-549/pytorch_model.bin\n",
      "Deleting older checkpoint [PubMedBERT_2021_test2/checkpoint-366] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 732\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       439\n",
      "           1       0.90      0.93      0.92       238\n",
      "           2       0.72      0.65      0.68        20\n",
      "           3       0.97      0.97      0.97        35\n",
      "\n",
      "    accuracy                           0.94       732\n",
      "   macro avg       0.89      0.88      0.88       732\n",
      "weighted avg       0.94      0.94      0.94       732\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to PubMedBERT_2021_test2/checkpoint-732\n",
      "Configuration saved in PubMedBERT_2021_test2/checkpoint-732/config.json\n",
      "Model weights saved in PubMedBERT_2021_test2/checkpoint-732/pytorch_model.bin\n",
      "Deleting older checkpoint [PubMedBERT_2021_test2/checkpoint-549] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from PubMedBERT_2021_test2/checkpoint-732 (score: 0.8817807275030399).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 732\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [92/92 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       439\n",
      "           1       0.90      0.93      0.92       238\n",
      "           2       0.72      0.65      0.68        20\n",
      "           3       0.97      0.97      0.97        35\n",
      "\n",
      "    accuracy                           0.94       732\n",
      "   macro avg       0.89      0.88      0.88       732\n",
      "weighted avg       0.94      0.94      0.94       732\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.31319618225097656,\n",
       " 'eval_accuracy': 0.9357923497267759,\n",
       " 'eval_precision': 0.8892072120160331,\n",
       " 'eval_recall': 0.8754524702819625,\n",
       " 'eval_f1': 0.8817807275030399,\n",
       " 'eval_0': 0.575,\n",
       " 'eval_1': 0.4,\n",
       " 'eval_2': 0.5833333333333334,\n",
       " 'eval_3': 0.5,\n",
       " 'eval_runtime': 14.6419,\n",
       " 'eval_samples_per_second': 49.993,\n",
       " 'eval_steps_per_second': 6.283,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate candidate model on test set\n",
    "train(train_set, test_set, 3.098e-5, 0.001, \"candidate_PubMedBERT_2021_test2\", 4, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "142b028b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext/resolve/main/config.json from cache at /home/elahehaa/.cache/huggingface/transformers/76e7b0967140f134278c3209cffe98f69eb013b9de505a434b3359c057aedaa3.2411d0fafcf181e9b95d9cb7972d93b27c57a2cb75819924f8fc7ec848b708f2\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext/resolve/main/pytorch_model.bin from cache at /home/elahehaa/.cache/huggingface/transformers/41964abe9a7c4ccbc21929b6d256f1b79a5a39566e329b380fae9d0bf622f7b7.ca2d7d719ab41e712011b6e8381af6b4be73841c1e580600c522386c5ed9b6f0\n",
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cuda_amp half precision backend\n",
      "loading configuration file https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext/resolve/main/config.json from cache at /home/elahehaa/.cache/huggingface/transformers/76e7b0967140f134278c3209cffe98f69eb013b9de505a434b3359c057aedaa3.2411d0fafcf181e9b95d9cb7972d93b27c57a2cb75819924f8fc7ec848b708f2\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext/resolve/main/pytorch_model.bin from cache at /home/elahehaa/.cache/huggingface/transformers/41964abe9a7c4ccbc21929b6d256f1b79a5a39566e329b380fae9d0bf622f7b7.ca2d7d719ab41e712011b6e8381af6b4be73841c1e580600c522386c5ed9b6f0\n",
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/elahehaa/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3657\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 916\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33melaheh-aghaarabi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/elahehaa/my_project_dir/wandb/run-20230527_141011-3m509wo5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/elaheh-aghaarabi/huggingface/runs/3m509wo5\" target=\"_blank\">candidate_PubMedBERT_2021_5/27/23</a></strong> to <a href=\"https://wandb.ai/elaheh-aghaarabi/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='916' max='916' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [916/916 14:23, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.387200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>458</td>\n",
       "      <td>0.169700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>687</td>\n",
       "      <td>0.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>916</td>\n",
       "      <td>0.044700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to candidate_PubMedBERT_2021_5/27/23/checkpoint-229\n",
      "Configuration saved in candidate_PubMedBERT_2021_5/27/23/checkpoint-229/config.json\n",
      "Model weights saved in candidate_PubMedBERT_2021_5/27/23/checkpoint-229/pytorch_model.bin\n",
      "Saving model checkpoint to candidate_PubMedBERT_2021_5/27/23/checkpoint-458\n",
      "Configuration saved in candidate_PubMedBERT_2021_5/27/23/checkpoint-458/config.json\n",
      "Model weights saved in candidate_PubMedBERT_2021_5/27/23/checkpoint-458/pytorch_model.bin\n",
      "Deleting older checkpoint [candidate_PubMedBERT_2021_5/27/23/checkpoint-229] due to args.save_total_limit\n",
      "Saving model checkpoint to candidate_PubMedBERT_2021_5/27/23/checkpoint-687\n",
      "Configuration saved in candidate_PubMedBERT_2021_5/27/23/checkpoint-687/config.json\n",
      "Model weights saved in candidate_PubMedBERT_2021_5/27/23/checkpoint-687/pytorch_model.bin\n",
      "Deleting older checkpoint [candidate_PubMedBERT_2021_5/27/23/checkpoint-458] due to args.save_total_limit\n",
      "Saving model checkpoint to candidate_PubMedBERT_2021_5/27/23/checkpoint-916\n",
      "Configuration saved in candidate_PubMedBERT_2021_5/27/23/checkpoint-916/config.json\n",
      "Model weights saved in candidate_PubMedBERT_2021_5/27/23/checkpoint-916/pytorch_model.bin\n",
      "Deleting older checkpoint [candidate_PubMedBERT_2021_5/27/23/checkpoint-687] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#deploy\n",
    "torch.manual_seed(42)\n",
    "class CustomTrainer(Trainer):\n",
    "    def calculate_class_weights(training_set):\n",
    "        labels = [set(training_set)]\n",
    "        class_distribution = [0]*len(labels)\n",
    "        for i in labels:\n",
    "            class_distribution[i] = training_set.count(i)\n",
    "        weights = []\n",
    "        class_distribution = np.array(class_distribution)\n",
    "        num_classes = len(labels)\n",
    "        weight = np.sum(class_distribution)/(num_classes * class_distribution)\n",
    "        return weight\n",
    "    def compute_custom_loss(model, inputs, return_outputs=False):\n",
    "        target = inputs.get('labels')\n",
    "        weights = calculate_class_weights(target)\n",
    "        ce_loss = nn.CrossEntropyLoss(weight=torch.tensor(weights))\n",
    "        outputs = model(*inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        probs = nn.functional.softmax(logits, dim = -1)\n",
    "        \n",
    "        loss = ce_loss(probs.view(-1, model.config.num_labels), target.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "def train(train_set, learning_rate, weight_decay, run_name, epochs, batch_size):\n",
    "    mlflow.start_run()\n",
    "\n",
    "    # Log training parameters\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"batch_size\", batch_size)\n",
    "    mlflow.log_param(\"num_epochs\", epochs)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir= run_name,\n",
    "        num_train_epochs= epochs,\n",
    "        learning_rate= learning_rate,\n",
    "        weight_decay= weight_decay,\n",
    "        per_device_train_batch_size= batch_size,\n",
    "        save_strategy= 'epoch' ,#IntervalStrategy.STEPS,\n",
    "        logging_strategy= 'epoch', #IntervalStrategy.STEPS,\n",
    "        remove_unused_columns=False,\n",
    "        save_total_limit = 1,\n",
    "        run_name= run_name,\n",
    "        fp16 = True,\n",
    "        #load_best_model_at_end=True,\n",
    "        #evaluation_strategy = 'epoch', #IntervalStrategy.STEPS,\n",
    "        metric_for_best_model = 'eval_f1',\n",
    "        seed = 42\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model_init= model_init,\n",
    "        args= training_args,\n",
    "        #train_tokenized for joined title and abstract, dataset['train'] for seperate title and abstract\n",
    "        train_dataset= train_set,\n",
    "        #use to create seperate title and abstract\n",
    "        data_collator = customized_data_collator,\n",
    "        compute_metrics= compute_metrics_fn,\n",
    "        #valid_tokenized for joined title and abstract, dataset['validation'] for seperate title and abstract\n",
    "        \n",
    "    )\n",
    "\n",
    "\n",
    "    trainer.train()\n",
    "    mlflow.end_run()\n",
    "\n",
    "mlflow.end_run()\n",
    "# Set the experiment path\n",
    "experiment_path = \"PubClassifier\"\n",
    "# Set the experiment\n",
    "mlflow.set_experiment(experiment_path)\n",
    "\n",
    "#train model on all available data to classify unseen 2022 data\n",
    "train(dataset['train'], 3.098e-5, 0.001, \"candidate_PubMedBERT_2021_5/27/23\", 4, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4615c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiments using 60/40\n",
    "run_name = \"ft_PubMedBert_all_lr46_13\"\n",
    "def model_init(num_labels, model_checkpoint):\n",
    "    return  AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels = num_labels)\n",
    "\n",
    "\n",
    "     \n",
    "def fine_tune( model_checkpoint, output_dir,  epochs,  num_labels, config = None):\n",
    "    \n",
    "    with wandb.init(config=config):\n",
    "    # set sweep configuration\n",
    "        config = wandb.config\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir = output_dir,\n",
    "            report_to='wandb',\n",
    "            learning_rate = config.learning_rate,\n",
    "            per_device_train_batch_size = batch_size,\n",
    "            per_device_eval_batch_size = batch_size,\n",
    "            num_train_epochs= epochs,\n",
    "            weight_decay = config.weight_decay,\n",
    "            #logging_steps = 'epoch',\n",
    "            load_best_model_at_end = True,\n",
    "            evaluation_strategy = 'epoch',\n",
    "            save_strategy= 'epoch',\n",
    "            save_total_limit = 1,\n",
    "            run_name= run_name\n",
    "            )\n",
    "\n",
    "        trainer = Trainer(\n",
    "        model=model_init(num_labels = num_labels, model_checkpoint = num_checkpoint),\n",
    "        args=training_args,\n",
    "        train_dataset=train_tokenized,\n",
    "        eval_dataset=valid_tokenized,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics = compute_metrics\n",
    "        #callbacks = [early_stopping],\n",
    "\n",
    "         )\n",
    "        a = trainer.train()\n",
    "    #wandb.finish()\n",
    "    return a\n",
    "\n",
    "fine_tune( model_checkpoint = model_checkpoint, output_dir = run_name,  num_labels = 4, epochs = 30,)\n",
    "#%tensorboard --logdir logs/fit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df092df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine-tuning for final classification with whole data\n",
    "run_name = \"ftw_PubMedBert_GRT_256_lr77_13_2\"\n",
    "def fine_tune(model_checkpoint, output_dir, lr, batch_size, epochs, weight_decay):\n",
    "    seed = 123\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels = 2)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = output_dir,\n",
    "        learning_rate = lr,\n",
    "        per_device_train_batch_size = batch_size,\n",
    "        per_device_eval_batch_size = batch_size,\n",
    "        num_train_epochs= epochs,\n",
    "        weight_decay = weight_decay,\n",
    "        #report_to='wandb',\n",
    "        #logging_steps = 'epoch',\n",
    "        #load_best_model_at_end = True,\n",
    "        #evaluation_strategy = 'epoch',\n",
    "        save_strategy= 'epoch',\n",
    "        save_total_limit = 1,\n",
    "        #run_name= run_name,\n",
    "        \n",
    "        )\n",
    "\n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    #eval_dataset=valid_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    #callbacks = [early_stopping],\n",
    "     )\n",
    "    a = trainer.train()\n",
    "    #wandb.finish()\n",
    "    return a\n",
    "\n",
    "fine_tune(model_checkpoint, \"ftw_PubMedBert_GRT_256_lr77_13_2\", 7e-7, 4, 12, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8951f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiments\n",
    "ft_model = AutoModelForSequenceClassification.from_pretrained(\"ft_all_PubMedBERT_selected32/checkpoint-465\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "clf = pipeline(\"text-classification\", model = ft_model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fb66e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-a7fd4db854b56d28\n",
      "Found cached dataset csv (/home/elahehaa/.cache/huggingface/datasets/csv/default-a7fd4db854b56d28/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae2f0cea56540a08c5de7d4417a3e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711cc08b26e64243921a910dc4cb5cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9562/3102222103.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#unknown_tokenized = dataset['unknown'].map(tokenize_data, batched = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"2022pubs_cleaned_sep.csv\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0munknown_tokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unknown'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-classification\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2815\u001b[0;31m             return self._map_single(\n\u001b[0m\u001b[1;32m   2816\u001b[0m                 \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m                 \u001b[0mwith_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwith_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m         }\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   3234\u001b[0m                         )  # Something simpler?\n\u001b[1;32m   3235\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m                             batch = apply_function_on_filtered_inputs(\n\u001b[0m\u001b[1;32m   3237\u001b[0m                                 \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m                                 \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mapply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwith_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3111\u001b[0m                 \u001b[0madditional_args\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3112\u001b[0;31m             \u001b[0mprocessed_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLazyDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3114\u001b[0m                 processed_inputs = {\n",
      "\u001b[0;32m/tmp/ipykernel_9562/3102222103.py\u001b[0m in \u001b[0;36mtokenize_data\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#dataset = load_data([\"2021pubs_cleaned.csv\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys_to_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "#deployment\n",
    "def load_data(unknown_file_path):\n",
    "    dataset = load_dataset(\"csv\", data_files = {'unknown': unknown_file_path})\n",
    "    return dataset\n",
    "\n",
    "#ft_model = AutoModelForSequenceClassification.from_pretrained(\"final_PubMedBERT/checkpoint-771\")\n",
    "#ft_model = AutoModelForSequenceClassification.from_pretrained(\"final_PubMedBERT_longer/checkpoint-771\")\n",
    "#ft_model = AutoModelForSequenceClassification.from_pretrained(\"final_PubMedBERT_2021/checkpoint-1785\")\n",
    "ft_model = AutoModelForSequenceClassification.from_pretrained(\"candidate_PubMedBERT_2021_5/27/23/checkpoint-916\")\n",
    "\n",
    "def tokenize_data(example):\n",
    "    return tokenizer(example['text'],  padding = True, truncation=True, max_length=max_length)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "#dataset = load_data([\"2021pubs_cleaned.csv\"])\n",
    "#unknown_tokenized = dataset['unknown'].map(tokenize_data, batched = True)\n",
    "dataset = load_data([\"2022pubs_cleaned_sep.csv\"])\n",
    "unknown_tokenized = dataset['unknown'].map(tokenize_data, batched = True)\n",
    "clf = pipeline(\"text-classification\", model = ft_model, tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiments\n",
    "def res(example):\n",
    "    return clf(example['text'],  truncation = True)\n",
    "#predictions = dataset['test'].map(res, batched = True)\n",
    "#print(predictions)\n",
    "predictions = {}\n",
    "for i in range(len(dataset['validation'])):\n",
    "    predictions[i] = clf(dataset['validation']['text'][i], truncation = 'longest_first', max_length = max_length)[0]['label']\n",
    "#for i in range(12, len(dataset['validation'])):\n",
    "    #print(i)\n",
    "    #predictions[i] = clf(dataset['validation']['text'][i], truncation = 'longest_first', max_length = 20)[0]['label']\n",
    "print (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5c0a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction for models processing title and abstract separately\n",
    "#ft_model = AutoModelForSequenceClassification.from_pretrained(\"PubMedBERT_2021_test/checkpoint-1098\")\n",
    "#ft_model = AutoModelForSequenceClassification.from_pretrained(\"PubMedBERT_2021_test/checkpoint-915\")\n",
    "#ft_model = AutoModelForSequenceClassification.from_pretrained(\"PubMedBERT_2021_test2/checkpoint-732\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "#predict 2022\n",
    "ft_model = AutoModelForSequenceClassification.from_pretrained(\"candidate_PubMedBERT_2021_5/27/23/checkpoint-916\")\n",
    "\n",
    "\n",
    "def predict(examples):\n",
    "    results = collections.defaultdict(list)\n",
    "    titles = [example['Title'] for example in examples]\n",
    "    abstracts = [example['Abstract'] for example in examples]\n",
    "    pmids = [example['PMID'] for example in examples]\n",
    "    #labels = [example['labels'] for example in examples]\n",
    "    tokenized_title = tokenizer(titles, padding='max_length', truncation=True, max_length=50)\n",
    "    tokenized_abstract = tokenizer(abstracts, padding='max_length', truncation=True, max_length=256)\n",
    "    \n",
    "    inputs = {\n",
    "        'input_ids': [a + b for a, b in zip(tokenized_title['input_ids'], tokenized_abstract['input_ids'])],\n",
    "        'attention_mask': [a + b for a, b in zip(tokenized_title['attention_mask'], tokenized_abstract['attention_mask'])],\n",
    "        'token_type_ids': [a + b for a, b in zip(tokenized_title['token_type_ids'], tokenized_abstract['token_type_ids'])]\n",
    "    }\n",
    "    \n",
    "    # Create input tensors\n",
    "    input_ids = torch.tensor(inputs['input_ids'])\n",
    "    attention_mask = torch.tensor(inputs['attention_mask'])\n",
    "    token_type_ids = torch.tensor(inputs['token_type_ids'])\n",
    "    \n",
    "    # Perform the prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = ft_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    \n",
    "    predictions = outputs.logits.argmax(dim=1).tolist()\n",
    "    #for pm, label, pred in zip(pmids, labels, predictions):\n",
    "        #results[pm].append(label)\n",
    "        #results[pm].append(pred)\n",
    "    #unknown   \n",
    "    for pm, pred in zip(pmids, predictions):\n",
    "        results[pm].append(pred)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def load_data(unknown_file_path):\n",
    "    dataset = load_dataset(\"csv\", data_files = {'unknown': unknown_file_path})\n",
    "    return dataset\n",
    "#predict unseen 2022\n",
    "#dataset = load_data([\"2022pubs_cleaned_sep.csv\"])\n",
    "#results , y_pred = predict(test_set)\n",
    "#results1 = predict([dataset['unknown'][int(i)] for i in range(5000)])\n",
    "#results2 = predict([dataset['unknown'][int(i)] for i in range(5000,10000)])\n",
    "#results3 = predict([dataset['unknown'][int(i)] for i in range(10000, 15000)])\n",
    "#results4 = predict([dataset['unknown'][int(i)] for i in range(15000, 20000)])\n",
    "#results5 = predict([dataset['unknown'][int(i)] for i in range(20000, 25000)])\n",
    "#results6 = predict([dataset['unknown'][int(i)] for i in range(25000, 30000)])\n",
    "results7 = predict([dataset['unknown'][int(i)] for i in range(30000, len(dataset['unknown']))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e38450d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33481"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "results.update(results1)\n",
    "results.update(results2)\n",
    "results.update(results3)\n",
    "results.update(results4)\n",
    "results.update(results5)\n",
    "results.update(results6)\n",
    "results.update(results7)\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4792ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving 2022 predictions\n",
    "df = pd.DataFrame.from_dict(results, orient = 'index')\n",
    "df.to_csv('pubPredictions_22.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a148d41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96583144 0.90756303 0.6        0.97142857] [0.92491468 0.96963563 0.98876404 0.99856528] [0.95067265 0.93506494 0.6        0.97142857]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def multi_class_performance(y_true, y_pred):\n",
    "\n",
    "    mcm = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    tps = mcm[:, 1, 1]\n",
    "    tns = mcm[:, 0, 0]\n",
    "\n",
    "    recall      = tps / (tps + mcm[:, 1, 0])         # Sensitivity\n",
    "    specificity = tns / (tns + mcm[:, 0, 1])         # Specificity\n",
    "    precision   = tps / (tps + mcm[:, 0, 1])         # PPV\n",
    "    return recall, specificity, precision\n",
    "\n",
    "recall , specificity, precision = multi_class_performance(y_true, y_pred)\n",
    "print(recall, specificity, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538c0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation of joined abstract and title\n",
    "max_length = 256\n",
    "ft_model = \"PubMedBERT_2021_2epoch/checkpoint-714\"\n",
    "#ft_model = 'final_PubMedBERT/checkpoint-771'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "clf = pipeline(\"text-classification\", model = ft_model, tokenizer = tokenizer)\n",
    "\n",
    "y_pred_true = collections.defaultdict(list)\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for i in range(len(dataset['validation'])):\n",
    "    p = clf(dataset['validation']['text'][i], truncation = True, max_length = max_length)[0]['label']\n",
    "    if p == 'LABEL_0':\n",
    "        y_pred_true[dataset['validation'][i]['PMID']].append(0)\n",
    "        y_pred.append(0)\n",
    "    elif p == 'LABEL_1':\n",
    "        y_pred_true[dataset['validation'][i]['PMID']].append(1)\n",
    "        y_pred.append(1)\n",
    "    elif p == 'LABEL_2':\n",
    "        print('hi')\n",
    "        y_pred_true[dataset['validation'][i]['PMID']].append(2)\n",
    "        y_pred.append(2)\n",
    "    else:\n",
    "        print('hi')\n",
    "        y_pred_true[dataset['validation'][i]['PMID']].append(3)\n",
    "        y_pred.append(3)\n",
    "    y_pred_true[dataset['validation'][i]['PMID']].append(dataset['validation'][i]['labels'])\n",
    "    y_true.append(dataset['validation'][i]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe854a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deployment\n",
    "y_pred = collections.defaultdict(list)\n",
    "for i in range(len(dataset['unknown'])):\n",
    "    p = clf(dataset['unknown']['text'][i], truncation = True, max_length = max_length)[0]\n",
    "    \n",
    "    if p['label'] == 'LABEL_0':\n",
    "        y_pred[dataset['unknown'][i]['PMID']].append(0)\n",
    "    elif p['label'] == 'LABEL_1':\n",
    "        y_pred[dataset['unknown'][i]['PMID']].append(1)\n",
    "    elif p['label'] == 'LABEL_2':\n",
    "        y_pred[dataset['unknown'][i]['PMID']].append(2)\n",
    "    else:\n",
    "        y_pred[dataset['unknown'][i]['PMID']].append(3)\n",
    "    y_pred[dataset['unknown'][i]['PMID']].append(p['score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026ed78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame.from_dict(y_pred, orient = 'index')\n",
    "print(prediction)\n",
    "prediction.to_csv('2022prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff3545",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame.from_dict(y_pred, orient = 'index', columns = ['Category'])\n",
    "predictions.index.names = ['PMID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a302c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(\"2021_RTDesignPreds_longer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ddedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prevention setup\n",
    "\n",
    "def load_data(train_file_path, valid_file_path):\n",
    "    if train_file_path and valid_file_path:\n",
    "        dataset = load_dataset(\"csv\", data_files = {'train': train_file_path, 'validation': valid_file_path})\n",
    "    elif not valid_file_path:\n",
    "        dataset = load_dataset(\"csv\", data_files = {'train': train_file_path})\n",
    "    return dataset\n",
    "model_checkpoint = 'google/bigbird-roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
    "max_length = 512\n",
    "def model_init():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_checkpoint,\n",
    "        num_labels=2,\n",
    "        #id2label={index: label for index, label in enumerate(labels.names)},\n",
    "        #label2id={label: index for index, label in enumerate(labels.names)}\n",
    "    )\n",
    "    return model\n",
    "model = model_init()\n",
    "def tokenize_data(example):\n",
    "    return tokenizer(example['text'],  padding = 'max_length', truncation=True, max_length=max_length)\n",
    "dataset = load_data(['trainPrevention.csv'],  ['validPrevention.csv'])\n",
    "train_tokenized = dataset['train'].map(tokenize_data, batched = True) \n",
    "valid_tokenized = dataset['validation'].map(tokenize_data, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3198e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine-tuning for final classification with whole data\n",
    "run_name = \"PubMedBert_prevention\"\n",
    "def fine_tune(model_checkpoint, output_dir, lr, batch_size, epochs, weight_decay):\n",
    "    seed = 123\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels = 2)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = output_dir,\n",
    "        learning_rate = lr,\n",
    "        per_device_train_batch_size = batch_size,\n",
    "        per_device_eval_batch_size = batch_size,\n",
    "        num_train_epochs= epochs,\n",
    "        weight_decay = weight_decay,\n",
    "        #report_to='wandb',\n",
    "        #logging_steps = 'epoch',\n",
    "        #load_best_model_at_end = True,\n",
    "        #evaluation_strategy = 'epoch',\n",
    "        save_strategy= 'epoch',\n",
    "        save_total_limit = 1,\n",
    "        #run_name= run_name,\n",
    "        \n",
    "        )\n",
    "\n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    #eval_dataset=valid_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    #callbacks = [early_stopping],\n",
    "     )\n",
    "    a = trainer.train()\n",
    "    #wandb.finish()\n",
    "    return a\n",
    "\n",
    "fine_tune(model_checkpoint,run_name, 7e-7, 4, 12, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f2c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning prevention\n",
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "}\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "parameters_dict = {\n",
    "    'epochs': {\n",
    "        'values': [1]\n",
    "        },\n",
    "    'batch_size': {\n",
    "        'values': [4, 8, 16]\n",
    "        },\n",
    "    'learning_rate': {\n",
    "        'distribution': 'log_uniform_values',\n",
    "        'min': 1e-4,\n",
    "        'max': 1e-2\n",
    "    },\n",
    "    'weight_decay': {\n",
    "        'values': [0.0, 0.01, 0.001]\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bbd06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"BigBird_prevention\"\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project = run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preventiohn hyperparam tuning\n",
    "run_name =  \"BigBird_prevention\"\n",
    "def finetune(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=run_name,\n",
    "            report_to='wandb', \n",
    "            num_train_epochs=config.epochs,\n",
    "            learning_rate=config.learning_rate,\n",
    "            weight_decay=config.weight_decay,\n",
    "            per_device_train_batch_size=config.batch_size,\n",
    "            per_device_eval_batch_size=16,\n",
    "            #save_strategy='epoch',\n",
    "            evaluation_strategy='epoch',\n",
    "            logging_strategy='epoch',\n",
    "            #load_best_model_at_end=True,\n",
    "            #remove_unused_columns=False,\n",
    "            #fp16=True,\n",
    "            #save_total_limit = 1,\n",
    "            run_name= run_name,\n",
    "        )\n",
    "        \n",
    "\n",
    "        trainer = Trainer(\n",
    "            model_init=model_init,\n",
    "            args=training_args,\n",
    "            train_dataset=train_tokenized,\n",
    "            eval_dataset=valid_tokenized,\n",
    "            compute_metrics=compute_metrics_fn\n",
    "        )\n",
    "\n",
    "\n",
    "        trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d420aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, finetune, count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a744d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#candidate model more epochs prevention\n",
    "run_name = 'BigBird_prevention'\n",
    "def train(learning_rate, weight_decay, run_name, epochs, batch_size):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir= run_name,\n",
    "        report_to='wandb', \n",
    "        num_train_epochs= epochs,\n",
    "        learning_rate= learning_rate,\n",
    "        weight_decay= weight_decay,\n",
    "        per_device_train_batch_size= batch_size,\n",
    "        per_device_eval_batch_size=16,\n",
    "        save_strategy='epoch',\n",
    "        evaluation_strategy='epoch',\n",
    "        logging_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        remove_unused_columns=False,\n",
    "        #fp16=True,\n",
    "        save_total_limit = 1,\n",
    "        run_name= run_name,\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model_init= model_init,\n",
    "        args= training_args,\n",
    "        train_dataset= train_tokenized,\n",
    "        eval_dataset= valid_tokenized,\n",
    "        compute_metrics= compute_metrics_fn\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "#prevention sweep 4\n",
    "train(7.779e-3, 0.01, run_name, 7, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a628cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate performance metrics experiment\n",
    "#performance metrics\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_checkpoint,\n",
    "        num_labels=2\n",
    "        #id2label={index: label for index, label in enumerate(labels.names)},\n",
    "        #label2id={label: index for index, label in enumerate(labels.names)}\n",
    "    )\n",
    "\n",
    "clf = pipeline(\"text-classification\", model = model_checkpoint, tokenizer = tokenizer)\n",
    "y_pred = {}\n",
    "y_true = {}\n",
    "for i in range(len(dataset['validation'])):\n",
    "    y_true[i] = dataset['validation']['labels'][i]\n",
    "    p = clf(dataset['validation']['text'][i], truncation = True, max_length = max_length)[0]['label']\n",
    "    #print(p)\n",
    "    if p == 'LABEL_0':\n",
    "        y_pred[i] = 0\n",
    "    elif p == 'LABEL_1':\n",
    "        y_pred[i] = 1\n",
    "    #elif p == 'LABEL_2':\n",
    "        #y_pred[i] = 2\n",
    "    #else:\n",
    "        #y_pred[i] = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fd8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(\"my name is elaheh\", pad_to_max_length=True, return_tensors=\"pt\")\n",
    "input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    max_length=256,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "for output in outputs:\n",
    "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda8a286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_binary(y_true, y_pred):\n",
    "    \n",
    "    tp, fn, tn, fp = 0, 0, 0, 0\n",
    "   \n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1 and y_pred[i] == 0:\n",
    "            fn += 1\n",
    "        if y_true[i] == 1 and y_pred[i] == 1:\n",
    "            tp += 1\n",
    "        if y_true[i] == 0 and y_pred[i] == 0:\n",
    "            tn += 1\n",
    "        if y_true[i] == 0 and y_pred[i] == 1:\n",
    "            fp += 1\n",
    "    return tp, fn, tn, fp\n",
    "\n",
    "def metric_binary(tp, fn, tn, fp):\n",
    "    try:    \n",
    "        recall = tp/(tp+fn)\n",
    "        specificity = tn/(tn+fp)\n",
    "        precision = tp/(tp+fp)\n",
    "        accuracy = (tp+tn)/(tp+fn+fp+tn)\n",
    "        f1 = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    \n",
    "    print(\"recall: \",recall, \"specificity: \",specificity, \"f1: \", f1, \"precision:\", precision, \"accuracy:\", accuracy,\n",
    "          \"false negatives: \", fn, \"false positive :\",fp, \"true positive:\", tp, \"true neg: \", tn)\n",
    "tp, fn , tn, fp = confusion_matrix_binary(y_true, y_pred)\n",
    "print(tp, fn , tn, fp)\n",
    "metric_binary(tp, fn , tn, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred):\n",
    "    \n",
    "    cm = dict()\n",
    "    cm = {'1':{'tp':0, 'fp':0, 'tn':0, 'fn':0},\n",
    "         '2': {'tp':0, 'fp':0, 'tn':0, 'fn':0},\n",
    "         '3':{'tp':0, 'fp':0, 'tn':0, 'fn':0},\n",
    "         }\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == y_pred[i]: \n",
    "            if y_true[i] == 1:\n",
    "                cm['1']['tp'] += 1\n",
    "            elif y_true[i] == 0:\n",
    "                cm['1']['tn'] += 1\n",
    "                cm['2']['tn'] += 1\n",
    "                cm['3']['tn'] += 1\n",
    "            elif y_true[i] == 2:\n",
    "                cm['2']['tp'] += 1\n",
    "            else:\n",
    "                cm['3']['tp'] += 1\n",
    "        elif y_true[i] != y_pred[i]:\n",
    "            if y_true[i] == 1:\n",
    "                cm['1']['fn'] += 1\n",
    "            elif y_true[i] == 0:\n",
    "                if y_pred[i] == 1:\n",
    "                    cm['1']['fp'] += 1\n",
    "                elif y_pred[i] == 2:\n",
    "                    cm['2']['fp'] += 1\n",
    "                elif y_pred[i] == 3:\n",
    "                    cm['3']['fp'] += 1\n",
    "            elif y_true[i] == 2:\n",
    "                cm['2']['fn'] += 1\n",
    "            else:\n",
    "                cm['3']['fn'] += 1\n",
    "            \n",
    "            \n",
    "        \n",
    "        #if y_true[i] == 1 and y_pred[i] == 1:\n",
    "            #tp += 1\n",
    "        #if y_true[i] == 0 and y_pred[i] == 0:\n",
    "            #tn += 1\n",
    "        #if y_true[i] == 0 and y_pred[i] == 1:\n",
    "            #fp += 1\n",
    "    return cm\n",
    "cm = dict()\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "for i , val in cm.items():\n",
    "    recall , specificity, precision, accuracy, f1 = 0,0,0,0,0\n",
    "    try:    \n",
    "        recall = val['tp']/(val['tp']+val['fn'])\n",
    "        specificity = val['tn']/(val['tn']+val['fp'])\n",
    "        precision = val['tp']/(val['tp']+val['fp'])\n",
    "        accuracy = (val['tp']+val['tn'])/(val['tp']+val['fn']+val['fp']+val['tn'])\n",
    "        f1 = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "\n",
    "    print(\"for class: \", i, \"recall: \",recall, \"specificity: \",specificity, \"f1: \", f1, \"precision:\", precision, \"accuracy:\", accuracy,\n",
    "  \"false negatives: \", val['fn'], \"false positive :\",val['fp'], \"true positive:\", val['tp'], \"true neg: \", val['tn'])\n",
    "\n",
    "        \n",
    "#tp, fn, tn, fp = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#try:    \n",
    "    #recall = tp/(tp+fn)\n",
    "    #specificity = tn/(tn+fp)\n",
    "    #precision = tp/(tp+fp)\n",
    "    #accuracy = (tp+tn)/(tp+fn+fp+tn)\n",
    "    #f1 = (2*precision*recall)/(precision+recall)\n",
    "\n",
    "#except ZeroDivisionError:\n",
    "    #pass\n",
    "    \n",
    "\n",
    "#print(\"recall: \",recall, \"specificity: \",specificity, \"f1: \", f1, \"precision:\", precision, \"accuracy:\", accuracy,\n",
    "      #\"false negatives: \", fn, \"false positive :\",fp, \"true positive:\", tp, \"true neg: \", tn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
